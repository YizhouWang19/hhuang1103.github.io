{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "european-halloween",
   "metadata": {},
   "source": [
    "# Week 2 - Data Prep 1\n",
    "After this week's lesson you should be able to:\n",
    "- Checking a columns data types and converting types\n",
    "- Rename a dataframe column \n",
    "- Handle missing data: \n",
    "    - Filter out missing data\n",
    "    - Replace values \n",
    "\n",
    "This week's lessons are adapted from:\n",
    "- [PPD599: Advanced Urban Analytics](https://github.com/gboeing/ppd599/tree/main/syllabus)\n",
    "- [Geo-Python Lesson 5](https://geo-python-site.readthedocs.io/en/latest/notebooks/L5/processing-data-with-pandas.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to start importing the libraries we need\n",
    "# all in one cell. \n",
    "# It is a good practice to keep all the imports in one cell so that\n",
    "# we can easily see what libraries we are using in the notebook.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# If you don't have numpy installed, you can install it via pip\n",
    "# !pip install numpy in a code cell\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-control",
   "metadata": {},
   "source": [
    "# 1. Data cleaning\n",
    "As you might have already seen, when we work with data, the initial dataset is not always in a shape where we can use it as is. \n",
    "\n",
    "Sometimes column names are misspelled or unclear, there may be missing values, or the format of each column is incorrect. Moreoever you may also have noticed that often we can extract information from columns that might make them easier to work with. All these steps can be considered part of a data cleaning or data wrangling process, where we get the dataset ready to be used more effectively for our analysis purposes. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-coordinator",
   "metadata": {},
   "source": [
    "## 1.1 Getting the data\n",
    "Let's say we want to compare the relationship between: \n",
    "1. the **total number of students in a general ed public school** \n",
    "2. the **money spent on new school construction and improvements in that school**. \n",
    "\n",
    "### School Construction Authority\n",
    "\n",
    "First, make sure you have the `Active_Projects_Under_Construction.csv` in your folder where this notebook is. It's from [Active Projects Under Construction](https://data.cityofnewyork.us/Housing-Development/Active-Projects-Under-Construction/8586-3zfm) from NYC's open data portal, but I've modified it a little.\n",
    "\n",
    "This is a dataset of new school projects (Capacity) and Capital Improvement Projects (CIP) currently under Construction, created by the School Construction Authority. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we are going to read a csv directly from the web\n",
    "## We are going to use the read_csv() function from the pandas library\n",
    "## \n",
    "\n",
    "projects_under_const = pd.read_csv('Active_Projects_Under_Construction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-steps",
   "metadata": {},
   "source": [
    "Also, go ahead and download the data dictionary `SCA Active Projects in Construction Data Dictionary.xlsx`. Data dictionaries often have explanations for what each column name represents and other useful information about the data. \n",
    "\n",
    "\n",
    "If you open up the data dictionary, does it correspond to the \"Columns in this Dataset\" section in the NYC OpenData's page on this dataset? No, right? We have to be careful about these inconsistencies, even in official portals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-orlando",
   "metadata": {},
   "source": [
    "Taking a look at the first five rows we can already see there is a lot of missing data in this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-convert",
   "metadata": {},
   "source": [
    "### Class size dataset\n",
    "Also download the `2021_-_2022_Average_Class_Size_by_School.csv` [2021 - 2022 Average Class Size by School](https://data.cityofnewyork.us/Education/2021-2022-Average-Class-Size-by-School/sgr7-hhwp) dataset, along with it's attachments. (Here, only `2021-2022 Average Class Size By School DD.xlsx` is the data dictionary, the other is the dataset as an excel spreadsheet). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size = pd.read_csv('2021_-_2022_Average_Class_Size_by_School.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-container",
   "metadata": {},
   "source": [
    "Here, most of the columns make sense to me. From the data dictionary, I can see that Program Type is coded as follows:\n",
    "\n",
    "- General Education (Gen Ed), \n",
    "- Integrated Co-Teaching (ICT), \n",
    "- Gifted and Talented (G&T), \n",
    "- Self-Contained (SC)\n",
    "- Accelerated (Acc)\"\n",
    "\n",
    "\n",
    "What does not make sense is the `Minimum Class Size` column, which seems to be the same as the maximum class size column in some cases. Therefore, I'll likely not use this column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-raleigh",
   "metadata": {},
   "source": [
    "## 1.2 Assessing Data Types\n",
    "One of the next things we'll check is the data type for each column to make sure that they are in the right format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-reliance",
   "metadata": {},
   "source": [
    "I would not necessarily change the data types for all columns (especially when there are a lot), **just the ones that you might potentially need**. \n",
    "\n",
    "Here, `Maximum Class Size` is an `object` format (I'm going to ignore `Minimum Class Size` for now), likely because the size is sometimes input as `<INT` and sometimes `INT`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3946abc",
   "metadata": {},
   "source": [
    "## 1.3 Replacing Data\n",
    "\n",
    "We went over replacing data last week. There are actually a few ways to do this: \n",
    "- `df.replace(to_replace=old_value, value=new_value)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a922242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size['Grade Level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Warning: inplace=True will modify the original column!\n",
    "class_size['Grade Level'].replace('K', '0', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd707285",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size['Grade Level'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30315a",
   "metadata": {},
   "source": [
    "You can also replace multiple values at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86afff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should probably not replace 'K-8 SC' with 0, but showing here for demonstration purposes\n",
    "class_size['Grade Level'].replace(['K','K-8 SC'], '0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810c6088",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size['Grade Level'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714574df",
   "metadata": {},
   "source": [
    "Note that we are not actually changing the original data! Just the version of the data that we have associated with this variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91290e22",
   "metadata": {},
   "source": [
    "We can also use \n",
    "* `df.loc[df['column_name'] == some_value, 'column_name'] = new_value`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e2379",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size.loc[class_size['Grade Level'] == 'K','Grade Level'] = '0'    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3f8f22",
   "metadata": {},
   "source": [
    "For replacing null values, see below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-gender",
   "metadata": {},
   "source": [
    "## 1.3 Changing data types\n",
    "Notice that we changed everything in \"Grade Level\" to numbers, but it's still showing up as an `object`.  Now let's try to change the data type for `Grade Level`. \n",
    "\n",
    "`.astype()` changes your column types for a particular column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94705628",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What I've done here is replace the old `max_class_size_clean` column with \n",
    "## a version of it that is an int\n",
    "class_size['Grade Level'] = class_size['Grade Level'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that `int` from above defaults to 64 bit integers. \n",
    "class_size['Grade Level'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab2482",
   "metadata": {},
   "source": [
    "## 1.5 Null values in pandas. \n",
    "\n",
    "There are two main ways to represent the absence of values in a cell in Pandas: \n",
    "- `None` means a missing entry, but it's not a numeric type. \n",
    "- `NaN` is used by Pandas for representing missing data in numeric columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e9cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-scheme",
   "metadata": {},
   "source": [
    "## 1.6 Handling missing data\n",
    "Now, let's say that our analysis depends knowing the year the data was created. There are a few ways of handling missing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-commissioner",
   "metadata": {},
   "source": [
    "### 1.6.1 Removing rows \n",
    "We can remove those rows with data missing from a column that we are planning to use in our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe12512",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_under_const[projects_under_const['data_year'].isna()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are going to use the isna() function to check if the data_year column has a NaN\n",
    "# isna() returns a boolean (True or False) for each row\n",
    "# and we are going to use that boolean to filter the dataframe. \n",
    "# We are going to keep only the rows where the data_year column is not a NaN\n",
    "\n",
    "projects_under_const_new = projects_under_const[projects_under_const['data_year'].isna()==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-belarus",
   "metadata": {},
   "source": [
    "### 1.6.2 Replacing missing data\n",
    "We can also replace the missing data with certain values: \n",
    "- We can replace the data with the mean of the non-NaN column values, for numerical values. (For instance, if our columns were something like \"adult heights\", then replacing the NaN with the mean values in the columns would allow us to leave the sample mean unchanged, which might be good for regression purposes). \n",
    "- We can also replace with the median (if you think there are outliers in the sample that might be skewing the mean)\n",
    "- Replacing with the mode (most frequent value) would make more sense if we think that there's some default value \n",
    "\n",
    "**What would you do here?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets the mode of the data_year column\n",
    "mode_year = projects_under_const['data_year'].mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fills the NaNs with the mode using the fillna() function\n",
    "# fillna() is a method that fills in missing values with a value of your choice\n",
    "projects_under_const['data_year'].fillna(mode_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write over the old data_year column with the new one\n",
    "projects_under_const['data_year'] = projects_under_const['data_year'].fillna(mode_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-freeware",
   "metadata": {},
   "source": [
    "# In-Class Exercise \n",
    "Using the `toy_transit.csv` dataset in this repo, identify and address the  missing data issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae336678",
   "metadata": {},
   "source": [
    "# Miniconda (optional)\n",
    "Some of you may have noticed that Anaconda takes up 3GB. If this is an issue on your computer, and if you have time right now: \n",
    "\n",
    "1) Follow [these instructions](https://docs.conda.io/projects/miniconda/en/latest/miniconda-install.html) to download Miniconda, which is a more lightweight Python environment. I think it's about 400 MB. \n",
    "2) Once you download miniconda, from your terminal, type \n",
    "`conda list`. \n",
    "If you get a list of installed packages, you've got conda installed. \n",
    "3) Now use the `gds_py_smaller.yml` file (make sure it's in the same directory as your current working directory!) and type\n",
    "\n",
    " `conda env create -f gds_py_smaller.yml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3d4b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc571d7ca67236538d190807671ab3198970b7d67f23d825ad141ff90f68066a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
