{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "announced-title",
   "metadata": {},
   "source": [
    "# A note about accessing the course files through Github\n",
    "\n",
    "All of the lectures notes will be posted on the [class Github repo](https://github.com/iamwfx/4680_5680_intro_uds). \n",
    "\n",
    "We are (probably) not going over git and Github during class. If you're familiar with git/Github, feel free to clone the repo to get the new lecture materials for each class. Otherwise, I recommend you do the following: \n",
    "- Create class folder and name it `Intro_UDS`\n",
    "- For each week, create a folder called `Week1`, `Week2`, etc. \n",
    "- To download the materials (Juputer notebook, data files, etc.), navigate to the file you want to download and select `Raw` above the view of the file. \n",
    "- Save this \"raw\" file in your class folder and **make sure it is in the proper file format**. For instance, if the file is `.ipynb` make sure you save the downloaded file as `.ipynb` (your computer might try to default to `.txt`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-tucson",
   "metadata": {},
   "source": [
    "# Learning goals\n",
    "After this week's lesson you should be able to:\n",
    "- Explain what a Pandas Series is and how to select, filter, and replace values in the series \n",
    "- Read and explore tabular data in Python using a Pandas DataFrame\n",
    "- Read and write datasets\n",
    "\n",
    "This week's lessons are adapted from:\n",
    "- [Geo-Python Lesson 5](https://geo-python-site.readthedocs.io/en/latest/lessons/L5/overview.html)\n",
    "- [Practical Data Sciece on Pandas DataFrames](https://www.practicaldatascience.org/html/30_pandas_dataframes.html)\n",
    "\n",
    "# Grading\n",
    "As a reminder, your in-class exercises will be graded on completion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af47e632",
   "metadata": {},
   "source": [
    "# Installing Pandas\n",
    "- First we'll need to install the `pandas` library if you are still using the `gds_py_reduced.yml` file that Jacob shared with you earlier today. \n",
    "- You can either do this in the Anaconda Navigator or \n",
    "- In your jupyter notebook, type \n",
    "```\n",
    "    `!pip install pandas` \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c1e07d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/wenfeixu/anaconda3/envs/gds_py/lib/python3.9/site-packages (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/wenfeixu/anaconda3/envs/gds_py/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/wenfeixu/anaconda3/envs/gds_py/lib/python3.9/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/wenfeixu/anaconda3/envs/gds_py/lib/python3.9/site-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/wenfeixu/anaconda3/envs/gds_py/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# The ! in front of pip is a special Jupyter Notebook command that allows you to run terminal commands from the notebook.\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "adequate-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's first import the pandas library\n",
    "### We will use the alias pd for pandas to make it easier to type. \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-diana",
   "metadata": {},
   "source": [
    "# 0. What is Pandas? \n",
    "\n",
    "[Pandas](http://pandas.pydata.org/) is a widely used Python library for data analysis. \n",
    "\n",
    "### Easy-to-use data structures\n",
    "In pandas, the data is typically stored in a data structure called a\n",
    "DataFrame that looks like a typical table with rows and columns (+\n",
    "indices and column names), where columns can contain data of different\n",
    "data types. Thus, it is similar in some sense to how data is stored in\n",
    "Excel or in R, which also uses a concept of a dataframe. In fact, Wes\n",
    "McKinney first [developed pandas as an alternative for\n",
    "R](https://blog.quantopian.com/meet-quantopians-newest-advisor-wes-mckinney/)\n",
    "to deal with different complex data structures.\n",
    "\n",
    "### Summary of the pandas data structure\n",
    "The below is a picture of how data is structured in a dataframe. You can see it is tabular structure with rows, columns, and a (row) index, which is in many ways similar to what you might be familiar with from a Excel or Google Spreadsheets. Using this structure, we can use operations like arithmetic, columns and rows selection, columns and rows addition etc.\n",
    "\n",
    "![Alt text](img/creating_dataframe1.png)\n",
    "\n",
    "### Combines functionalities from many Python modules\n",
    "\n",
    "pandas takes advantage of the [NumPy](http://www.numpy.org/) module\n",
    "under the hood, which is mostly written in C. This makes it a fast and\n",
    "powerful library that can efficiently handle even very large datasets.\n",
    "pandas offers an easier and more intuitive syntax to do data analysis\n",
    "and manipulation using either Numpy functionalities in the background or dedicated functionalities written explicitly for pandas.\n",
    "\n",
    " However, pandas is much more than an easier-to-use Numpy as it also combines many functionalities from other Python libraries such as [matplotlib (plotting)](https://matplotlib.org/) and [scipy(mathematics, science, engineering)](https://www.scipy.org/). Thus, you can use many of the features included in those packages without importing them at all.\n",
    "\n",
    "### Supports data read/write from multiple formats\n",
    "One of the most useful features of pandas is its ability to read data\n",
    "from numerous different data formats directly. For example, pandas\n",
    "supports reading and writing data from/to:\n",
    "\n",
    "-   CSV\n",
    "-   JSON\n",
    "-   HTML\n",
    "-   MS Excel\n",
    "-   HDF5\n",
    "-   Stata\n",
    "-   SAS\n",
    "-   Python Pickle format\n",
    "-   SQL (Postgresql, MySQL, Oracle, MariaDB, etc.)\n",
    "\n",
    "You can view the full list of supported data formats from the [pandas\n",
    "docs](https://pandas.pydata.org/docs/user_guide/io.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-cathedral",
   "metadata": {},
   "source": [
    "# 1. DataFrames\n",
    "Pandas DataFrames are tabular (as in table) data consisting of a collection of Series in which each column is a Pandas series. It is the central data structure used in most analysis using the Pandas library. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-lemon",
   "metadata": {},
   "source": [
    "First, let's read in our data using the pandas function `.read_csv()`. \n",
    "\n",
    "One of the nifty things about reading data in pandas is that it's designed to read many different types data sources, from files, to QL databases, and URLs. Here are a few to know about: \n",
    "- `pd.read_csv`: Read in a comma-separated-value file\n",
    "- `pd.read_excel`: Read in an Excel (`.xls` and `.xlsx`) spreadsheet\n",
    "- `pd.read_stata`: Read Stata (`.dta`) datasets\n",
    "- `pd.read_hdf`: Read HDF (`.hdf`) datasets\n",
    "- `pd.read_sql`: Read from a SQL database\n",
    "- `pd.read_html`: Read from the `html` tags of an HTML file\n",
    "\n",
    "Similarly, you can write a dataframe to many formats: (`df` here is the name of a dataframe)\n",
    "- `df.to_csv`: Write to a comma-separated-value file\n",
    "- `df.to_excel`: Write to an Excel (.xls and .xlsx) spreadsheet\n",
    "- `df.to_stata`: Write to a stata (.dta) dataset\n",
    "- `df.to_hdf`: Write to an HDF (.hdf) dataset\n",
    "- `df.to_sql`: Write to a SQL database\n",
    "- `df.to_html`: Write to an HTML table. \n",
    "\n",
    "\n",
    "Check out the [Pandas documentation on input/output](https://pandas.pydata.org/docs/reference/io.html) to see all the possible functions for reading data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-monte",
   "metadata": {},
   "source": [
    "## 1.1 Reading a file\n",
    "Download the `msa_by_pop.csv` in this week's folder. We are first going to read this CSV as DataFrame into Pandas.\n",
    "\n",
    "The function `.read_csv()` takes a file path as a string (read: text). If you have saved `msa_by_pop.csv` in the same folder as this notebook, then all you will need to input as your path is `msa_by_pop.csv`. \n",
    "\n",
    "(If you had saved your CSV within a sub-directory called `Data`, then to access this data file you'd need to input `Data/msa_by_pop.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop = pd.read_csv('msa_by_pop.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b03f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d12194",
   "metadata": {},
   "source": [
    "## 1.2 File Paths\n",
    "`'msa_by_pop.csv'` is our file path. A file path is a string that tells the computer where to find a file. The file path above is a relative path, meaning it is relative to the location of this notebook. If you move this notebook to a different folder, the relative path will no longer work. An absolute path is a path that is not relative to the location of the notebook. An absolute path will work no matter where the notebook is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07854f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For my computer, I can also read in the same dataset by using the absolute path.\n",
    "msa_by_pop = pd.read_csv('/Users/wenfeixu/Documents/GITHUB/4680_5680_intro_uds/Week1/msa_by_pop.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be58aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-tactics",
   "metadata": {},
   "source": [
    "## 1.3 Exploring our data\n",
    "You can see here that (in addition to the formatting of tabular data in Jupyter) the main difference between this and a series is that we have multiple columns with column labels. So the dataframe structure consists of: \n",
    "- An index, with index labels (here the labels are just `0`,`1`,...,`383`)\n",
    "- Columns, with column labels (here `MSA`, `population_2020`,`perc_change`)\n",
    "- And the data, which are the values in each row. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-affect",
   "metadata": {},
   "source": [
    "We can use `.index` to get all the index values in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.index\n",
    "## Ok, here it's just the RangeIndex, which is the default index for pandas dataframes. \n",
    "## Pandas isn't printing the entire index, but we can see that it starts at 0 and ends at 384."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029b5ae0",
   "metadata": {},
   "source": [
    "Now, in addition to `.index` we can also see all the columns in our DataFrame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-rachel",
   "metadata": {},
   "source": [
    "Now, to see the datatypes for each column, we use `.dtypes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-juvenile",
   "metadata": {},
   "source": [
    "One common function used to explore the data is called `.head()` that reveals the first 5 rows of the Dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-blackjack",
   "metadata": {},
   "source": [
    "If you start to type `msa_by_pop.head(` without finishing the parens you can see the inputs required of the function: \n",
    "\n",
    "\n",
    "<img src=\"img/func_arg.png\" alt=\"drawing\" width=\"400\" style=\"display: block; margin: 0 auto\"/>\n",
    "\n",
    "\n",
    "This shows us that that `.head()` by default show 5 rows, but you can also optionally adjust this by specifying another integer. For instance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This gives us the first 10 rows\n",
    "msa_by_pop.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-companion",
   "metadata": {},
   "source": [
    "`.sample()` gives us a random selection of rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-shopping",
   "metadata": {},
   "source": [
    "The function `.shape` gives us the number of `(rows,columns)` in our dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-cornell",
   "metadata": {},
   "source": [
    "The function `.len()` measures the length of a selection. Applying this to the DataFrame gives you the number of rows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(msa_by_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-ancient",
   "metadata": {},
   "source": [
    "Applying it to the columns gives us the number of columns we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(msa_by_pop.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-child",
   "metadata": {},
   "source": [
    "`.describe()` provides some basic descriptive statistics for our dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-charity",
   "metadata": {},
   "source": [
    "`.sort-values()` sorts your DataFrame by a certain column. If you column is numeric, it will sort the values from smallest to largest. If your column is a string, it will sort alphabetically.\n",
    "\n",
    "The index values will be sorted along with the rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sorts the dataframe by the population_2021_est column, from smallest to largest\n",
    "# Note that the original dataframe is not changed \n",
    "# but that the index values now reflect the sorted order. \n",
    "msa_by_pop.sort_values('population_2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-connection",
   "metadata": {},
   "source": [
    "Adding the `ascending=False` input in your function will sort from largest to smallest or end of alphabet to beginning, depending on your column data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.sort_values('population_2020',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-blues",
   "metadata": {},
   "source": [
    "## 2.4 Selecting columns and rows\n",
    "Since we have column and row indexes, we can select subsets of the dataframe using the .loc method.\n",
    "Let's select the row with index value 0, and all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.loc[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-taiwan",
   "metadata": {},
   "source": [
    "For `.iloc` we can select rows and columns now by their position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember integer ranges are exclusive of the last value!\n",
    "msa_by_pop.iloc[0:5,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-keeping",
   "metadata": {},
   "source": [
    "Similarly, using `.loc` we can select rows and columns by their names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our rows are index by integers, when we can use the .loc method to select rows, \n",
    "# it's the same as .iloc\n",
    "msa_by_pop.loc[0:5,['Rank','MSA','population_2020']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-belgium",
   "metadata": {},
   "source": [
    "You can always leave out the column argument in either `.loc` or `.iloc` in order to select all columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.loc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-regard",
   "metadata": {},
   "source": [
    "But to do the same with columns you'll first have to specify that you want all the rows with `:` . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.loc[:,['Rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop.iloc[:,[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-roots",
   "metadata": {},
   "source": [
    "With the square brackets `[]` you can provide a row or column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e42a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop['Rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c34f045",
   "metadata": {},
   "source": [
    "If you put the column name in a list, you get back a dataframe instead of a series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop[['Rank']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fb2221",
   "metadata": {},
   "source": [
    "This list can have more than one element, of course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop[['Rank','population_2020']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-plaza",
   "metadata": {},
   "source": [
    "## 2.5 Filtering\n",
    "We can filter the dataframe by expressions. Filtering in pandas is done with a boolean expression. The expression is evaluated for each row in the dataframe, and only rows where the expression evaluates to `True` are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A boolean expression is one that evaluates to either True or False.\n",
    "# Here we are asking if the value in the Rank column is greater than 300.\n",
    "\n",
    "msa_by_pop.loc[msa_by_pop['Rank']>300]\n",
    "# Yes, msa_by_pop['Rank'] does also select the column, \n",
    "# but notice that it gives a Series instead of a dataframe one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7039f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This expression finds all the rows where the value in the Rank column is greater than 300,\n",
    "msa_by_pop['Rank']>300\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-storm",
   "metadata": {},
   "source": [
    "In order to filter by more than one condition, you must: \n",
    "1. Put all conditions in `()`\n",
    "2. Separate the condtions by: \n",
    "\n",
    "    a. `|` if an `OR` condition     \n",
    "    b. `&` if an `AND` condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop[(msa_by_pop['Rank']>300) & (msa_by_pop['MSA'].str.contains('NY'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop[(msa_by_pop['Rank']>300) | (msa_by_pop['MSA'].str.contains('NY'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-delta",
   "metadata": {},
   "source": [
    "## 2.6 Modifying elements\n",
    "Essentially, in the same way that we can select elements we can also update them using the same logic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter for population value\n",
    "msa_by_pop.loc[msa_by_pop['population_2020']==20140470,'population_2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8459fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same as above, but we are assigning the value 20000000 to the population_2021_est column\n",
    "msa_by_pop.loc[msa_by_pop['population_2020']==20140470,'population_2020'] = 20000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-fossil",
   "metadata": {},
   "source": [
    "## 2.7 Pandas Arithmetics\n",
    "Pandas arithmetics are vectorized, meaning that the operation is applied to each element in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a3ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas arithmetics are vectorized, meaning that the operation is applied to each element in the column\n",
    "msa_by_pop['population_2020'] / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0565ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can assign the result of this operation to a new column\n",
    "msa_by_pop['population_2020_millions'] = msa_by_pop['population_2020'] / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff73c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This multiplies the population_2020 column by 2 \n",
    "msa_by_pop['population_2020'] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90096da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes the square of the population_2020 column\n",
    "msa_by_pop['population_2020'] **2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65db720",
   "metadata": {},
   "source": [
    "We can find the sum by using the sum method. Note that the sum method ignores missing values by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop['population_2020'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7088ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop['population_2020'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcac73e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop['population_2020'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf333ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_by_pop['population_2020'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-pattern",
   "metadata": {},
   "source": [
    "# 3. Good Coding Practices\n",
    "\n",
    "The following are some good practices for writing more legible Jupyter notebooks. Often, we don't necessarily realize that code we write isn't immediately interpretable to readers. To make code more easily interpreted, we will often explain through markdown text or comments what we are doing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-gross",
   "metadata": {},
   "source": [
    "## 3.1 Markdown and explanatory cells\n",
    "As you can see in this notebook, there are many \"Markdown\" cells surrounding our actual code. The markdown I have here describes the purpose of each code cell and what I wanted to do with it. \n",
    "\n",
    "I often organize my notebooks by header size `#`, `##` etc, and by numbering the different sections. This can be helpful if you're writing an especially long notebook. \n",
    "\n",
    "Here's a [guide on how to write in Markdown](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-grain",
   "metadata": {},
   "source": [
    "## 3.2 Indents\n",
    "Indents are very important in python. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d24ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indents are important in Python! \n",
    "# They tell Python what code is part of a function or loop.\n",
    "# This is a for loop.\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "# This will give you an error: \n",
    "for i in range(5):\n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5810c457",
   "metadata": {},
   "source": [
    "## 3.3 Commenting\n",
    "Code comments are lines that start with a #. They are not executed by Python. They are used to explain what the code does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-quest",
   "metadata": {},
   "source": [
    "You can see that sometimes I have small notes in there that maybe didn't need to go into the markdown cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code comment\n",
    "msa_by_pop[(msa_by_pop['Rank']>300) & (msa_by_pop['MSA'].str.contains('NY')) & (msa_by_pop['population_2020']>100000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-berry",
   "metadata": {},
   "source": [
    "## 3.4 Selecting variable names\n",
    "There are two aspects of selecting variable names we're going to go over today: \n",
    "1. What to name your variables or function\n",
    "2. How to name a multi-word variable or function\n",
    "\n",
    "### 3.3.1\n",
    "A good variable name should: \n",
    "- Be clear and concise.\n",
    "- Be written in English. A general coding practice is to write code with variable names in English, as that is the most likely common language between programmers. Thus, variable names such as muuttuja (which is also not a good name on other levels) should be avoided.\n",
    "- Not contain special characters. Python supports use of special characters by way of various encoding options that can be given in a program. That said, it is better to avoid variables such as lämpötila because encoding issues can arise in some cases. Better to stick to the standard printable ASCII character set to be safe.\n",
    "- Not conflict with any Python keywords, such as for, True, False, and, if, or else. These are reserved for special operations in Python and cannot be used as variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not do this: \n",
    "finnishmeteorlogicalinstituteobservationstationidentificationnumber = \"101533\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or this: \n",
    "f = \"101533\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something that is as short as possible while still being descriptive is best\n",
    "sid = \"101533\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-checklist",
   "metadata": {},
   "source": [
    "### 3.3.2 Snake case and camel case\n",
    "There are two general ways of connecting variable and function names that contain more than one word. \n",
    "\n",
    "You can see from the above exercise that I've named my DataFrame `msa_by_pop`. Connecting words by `_`  is called \"Snake Case\". \n",
    "\n",
    "Another convention is to use capital letters to start new words. `MsaByPop` could be another way to name our variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-sperm",
   "metadata": {},
   "source": [
    "# 4. In-Class Exercises\n",
    "Each week, we will have in-class exercises that give you some pratice on the concepts learned in class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-welding",
   "metadata": {},
   "source": [
    "## 4.1. Exercise 1 \n",
    "We are going to use the `msa_by_pop` data frame we created above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53eb09c1-7281-4984-bc15-49815beb91f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>MSA</th>\n",
       "      <th>population_2021_est</th>\n",
       "      <th>population_2020</th>\n",
       "      <th>perc_change</th>\n",
       "      <th>Encompassing_combined_statistical_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>New York–Newark–Jersey City, NY-NJ MSA</td>\n",
       "      <td>19557311.0</td>\n",
       "      <td>20081935.0</td>\n",
       "      <td>−2.61%</td>\n",
       "      <td>New York–Newark, NY-NJ-CT-PA CSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles–Long Beach–Anaheim, CA MSA</td>\n",
       "      <td>12872322.0</td>\n",
       "      <td>13200998.0</td>\n",
       "      <td>−2.49%</td>\n",
       "      <td>Los Angeles–Long Beach, CA CSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Chicago–Naperville–Elgin, IL-IN MSA</td>\n",
       "      <td>9274140.0</td>\n",
       "      <td>9449351.0</td>\n",
       "      <td>−1.85%</td>\n",
       "      <td>Chicago–Naperville, IL-IN-WI CSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dallas–Fort Worth–Arlington, TX MSA</td>\n",
       "      <td>7943685.0</td>\n",
       "      <td>7637387.0</td>\n",
       "      <td>+4.01%</td>\n",
       "      <td>Dallas–Fort Worth, TX-OK CSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Houston–Pasadena–The Woodlands, TX MSA</td>\n",
       "      <td>7368466.0</td>\n",
       "      <td>7149642.0</td>\n",
       "      <td>+3.06%</td>\n",
       "      <td>Houston–Pasadena, TX CSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>383</td>\n",
       "      <td>Lewiston, ID-WA MSA</td>\n",
       "      <td>65512.0</td>\n",
       "      <td>64375.0</td>\n",
       "      <td>+1.77%</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>384</td>\n",
       "      <td>Enid, OK MSA</td>\n",
       "      <td>61920.0</td>\n",
       "      <td>62846.0</td>\n",
       "      <td>−1.47%</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>385</td>\n",
       "      <td>Walla Walla, WA MSA</td>\n",
       "      <td>61890.0</td>\n",
       "      <td>62584.0</td>\n",
       "      <td>−1.11%</td>\n",
       "      <td>Kennewick–Richland-Walla Walla, WA CSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>386</td>\n",
       "      <td>Carson City, NV MSA</td>\n",
       "      <td>58130.0</td>\n",
       "      <td>58639.0</td>\n",
       "      <td>−0.87%</td>\n",
       "      <td>Reno–Carson City–Gardnerville Ranchos, NV-CA CSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>387</td>\n",
       "      <td>Eagle Pass, TX</td>\n",
       "      <td>57843.0</td>\n",
       "      <td>57887.0</td>\n",
       "      <td>−0.08%</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>387 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank                                     MSA  population_2021_est  \\\n",
       "1       1  New York–Newark–Jersey City, NY-NJ MSA           19557311.0   \n",
       "2       2  Los Angeles–Long Beach–Anaheim, CA MSA           12872322.0   \n",
       "3       3     Chicago–Naperville–Elgin, IL-IN MSA            9274140.0   \n",
       "4       4     Dallas–Fort Worth–Arlington, TX MSA            7943685.0   \n",
       "5       5  Houston–Pasadena–The Woodlands, TX MSA            7368466.0   \n",
       "..    ...                                     ...                  ...   \n",
       "383   383                     Lewiston, ID-WA MSA              65512.0   \n",
       "384   384                            Enid, OK MSA              61920.0   \n",
       "385   385                     Walla Walla, WA MSA              61890.0   \n",
       "386   386                     Carson City, NV MSA              58130.0   \n",
       "387   387                          Eagle Pass, TX              57843.0   \n",
       "\n",
       "     population_2020 perc_change  \\\n",
       "1         20081935.0      −2.61%   \n",
       "2         13200998.0      −2.49%   \n",
       "3          9449351.0      −1.85%   \n",
       "4          7637387.0      +4.01%   \n",
       "5          7149642.0      +3.06%   \n",
       "..               ...         ...   \n",
       "383          64375.0      +1.77%   \n",
       "384          62846.0      −1.47%   \n",
       "385          62584.0      −1.11%   \n",
       "386          58639.0      −0.87%   \n",
       "387          57887.0      −0.08%   \n",
       "\n",
       "               Encompassing_combined_statistical_area  \n",
       "1                    New York–Newark, NY-NJ-CT-PA CSA  \n",
       "2                      Los Angeles–Long Beach, CA CSA  \n",
       "3                    Chicago–Naperville, IL-IN-WI CSA  \n",
       "4                        Dallas–Fort Worth, TX-OK CSA  \n",
       "5                            Houston–Pasadena, TX CSA  \n",
       "..                                                ...  \n",
       "383                                               NaN  \n",
       "384                                               NaN  \n",
       "385            Kennewick–Richland-Walla Walla, WA CSA  \n",
       "386  Reno–Carson City–Gardnerville Ranchos, NV-CA CSA  \n",
       "387                                               NaN  \n",
       "\n",
       "[387 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa_by_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-curve",
   "metadata": {},
   "source": [
    "Which is the MSA with the 10th largest population for 2020? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-dispute",
   "metadata": {},
   "source": [
    "Select the smallest 10 MSAs by 2020 Census population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-boulder",
   "metadata": {},
   "source": [
    "Find the total 2020 Census population of these 384 MSAs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-egyptian",
   "metadata": {},
   "source": [
    "Based on the population in 2020 and assuming a 2% population increase across all cities, let's estimate the population in 2022 using the following function: \n",
    "\n",
    "$$\n",
    "pop_{year2020+t} =pop_{year2020}*(1+ {\\% change})^t\n",
    "$$\n",
    "\n",
    "\n",
    "where  $\\% change$ is positive 2%. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5784a3d",
   "metadata": {},
   "source": [
    "First, what's t? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here\n",
    "t= "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-triangle",
   "metadata": {},
   "source": [
    "Now create another column called `population_2022_estimate` and estimate the 2022 population counts using the formula above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code here\n",
    "msa_by_pop['population_2022_estimate']= \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc571d7ca67236538d190807671ab3198970b7d67f23d825ad141ff90f68066a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
